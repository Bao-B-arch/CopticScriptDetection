---
title: "Coptic OCR"
lang: fr
author: "Antenainaskara"
echo: False
format: 
    pdf:
        toc: true
        toc-depth: 2
        toc-title: Table des Matières
        number-sections: true
        colorlinks: true
        default-image-extension: tex
        fig-pos: 'h'
    revealjs:
        toc-depth: 2
        toc-title: Table des Matières
        slide-level: 3
jupyter: python3
---

::: {.content-visible when-format="pdf"}

\newpage

:::

```{python}
import yaml

with open("report/report.yaml", "r") as file:
    data = yaml.safe_load(file)

database_desc = data["DATABASE_DESCRIPTION"]
features_desc = data["FEATURES_DESCRIPTION"]
```

## Description de la base de données

```{python}
train_percent = f"{database_desc['TRAIN_SIZE']['percent']:.2f}"
test_percent = f"{database_desc['TEST_SIZE']['percent']:.2f}"
```

La base de données se compose d'images `28x28` en nuances de gris.

| Jeu de données | Nombre d'images |
|--|--|
| TOTAL | `{python} database_desc["SIZE"]`
| TRAIN | `{python} database_desc["TRAIN_SIZE"]["value"]` (`{python} train_percent`%)
| TEST | `{python} database_desc["TEST_SIZE"]["value"]` (`{python} test_percent`%)

### Valeurs cibles

::: {.content-visible when-format="pdf"}

On dénombre `32` lettres dans l'alphabet copte. Deux, `eta` et `sampi`, ont été retirées car n'ayant pas assez d'images associées (respectivement `7` et `2`).

:::

![distribution des lettres](./graphs/split.svg){#fig-split}


::: {.content-visible when-format="pdf"}

\newpage

:::

## Description des features

Chaque image est découpée en `{python} features_desc["NB_PATCHES"]` patches et la moyenne de chaque patch est retenue donnant `{python} features_desc["NB_PATCHES"]` features par image.

Exemple pour une lettre `qima`:

::: {layout-ncol=2}

![lettre](./Images_Traitees/qima/objet_1_585.png){#fig-letter width=40%}

![features](./export/qima/example_qima.png){#fig-features width=40%}

:::

## Transformation des données

Afin d'éviter des problèmes numériques et des imprécisions lors de l'apprentissage, il est nécessaire de transformer les données pour les rapprocher de l'intervale `[-1, 1]`.

Il sera utilisé un Standard Scaler: $z = \frac{x - m}{s}$ avec $m$ la moyenne et $s$ l'écart-type.

### Analyse de viabilité du scaler

Un Standard Scaler est simple mais sensible aux valeurs aberrantes. Une analyse de la proportion de potentielles valeurs aberrantes est effectuée afin de vérifier si ce scaler est correct.

![Analyse des outliers](./graphs/scaling.svg){#fig-scaling}

::: {.content-visible when-format="revealjs"}

---

:::

::: {.content-visible when-format="pdf"}

\newpage

:::

```{python}
nb_outliers = features_desc["OUTLIERS_ANALYSIS"]["nb_outliers"]
pc_outliers = features_desc["OUTLIERS_ANALYSIS"]["percent"]

import pandas as pd
df_outlier = pd.DataFrame({"nb_outliers": nb_outliers, "percent": pc_outliers})
df_outlier = df_outlier.sort_values(by="nb_outliers")
print(df_outlier)

features_over = df_outlier.index[df_outlier.loc[:, "percent"] > 5.0]
```

Bien qu'il y ait `{python} len(features_over)` features dépassant les `5%` d'outliers, on considère que la transformation des données est valide.