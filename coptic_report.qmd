---
title: "Coptic OCR"
lang: fr
author: "Antenainaskara"
echo: False
format: 
    pdf:
        toc: true
        toc-depth: 2
        toc-title: Table des Matières
        number-sections: true
        colorlinks: true
        default-image-extension: tex
        fig-pos: 'h'
    revealjs:
        toc-depth: 2
        toc-title: Table des Matières
        slide-level: 3
jupyter: python3
---

::: {.content-visible when-format="pdf"}

\newpage

:::

```{python}
import yaml

with open("report/report.yaml", "r") as file:
    data = yaml.safe_load(file)

database_desc = data["DATABASE_DESCRIPTION"]
features_desc = data["FEATURES_DESCRIPTION"]
metrics_desc = data["MODEL_DESCRIPTION"]["METRICS"]
params_desc = data["MODEL_DESCRIPTION"]["PARAMS"]
```

## Description de la base de données

```{python}
train_percent = f"{database_desc['TRAIN_SIZE']['percent']:.2f}"
test_percent = f"{database_desc['TEST_SIZE']['percent']:.2f}"
```

La base de données se compose d'images `28x28` en nuances de gris.

| Jeu de données | Nombre d'images |
|--|--|
| TOTAL | `{python} database_desc["SIZE"]`
| TRAIN | `{python} database_desc["TRAIN_SIZE"]["value"]` (`{python} train_percent`%)
| TEST | `{python} database_desc["TEST_SIZE"]["value"]` (`{python} test_percent`%)

### Valeurs cibles

```{python}
list_letter = database_desc["LETTER_REMOVED"]

str_letter = ", ".join([f"`{l}`" for l in list_letter])
images_letter = ", ".join([f"{l}" for l in list_letter.values()])
```

::: {.content-visible when-format="pdf"}

On dénombre `32` lettres dans l'alphabet copte. `{python} str_letter` ont été retirées car n'ayant pas assez d'images associées (respectivement `{python} images_letter`).

:::

![distribution des lettres](./graphs/split.svg){#fig-split}


::: {.content-visible when-format="pdf"}

\newpage

:::

## Description des features

Chaque image est découpée en `{python} features_desc["NB_PATCHES"]` patches et la moyenne de chaque patch est retenue donnant `{python} features_desc["NB_PATCHES"]` features par image.

Exemple pour une lettre `qima`:

::: {layout-ncol=2}

![lettre](./Images_Traitees/qima/objet_1_585.png){#fig-letter width=40%}

![features](./export/qima/example_qima.png){#fig-features width=40%}

:::

## Transformation des données

Afin d'éviter des problèmes numériques et des imprécisions lors de l'apprentissage, il est nécessaire de transformer les données pour les rapprocher de l'intervale `[-1, 1]`.

Il sera utilisé un Standard Scaler: $z = \frac{x - m}{s}$ avec $m$ la moyenne et $s$ l'écart-type.

### Analyse de viabilité du scaler

Un Standard Scaler est simple mais sensible aux valeurs aberrantes. Une analyse de la proportion de potentielles valeurs aberrantes est effectuée afin de vérifier si ce scaler est correct.

![Analyse des outliers](./graphs/scaling.svg){#fig-scaling}

::: {.content-visible when-format="revealjs"}

---

:::

::: {.content-visible when-format="pdf"}

\newpage

:::

```{python}
nb_outliers = features_desc["OUTLIERS_ANALYSIS"]["nb_outliers"]
pc_outliers = features_desc["OUTLIERS_ANALYSIS"]["percent"]

import pandas as pd
df_outlier = pd.DataFrame({"nb_outliers": nb_outliers, "percent": pc_outliers})
df_outlier = df_outlier.sort_values(by="nb_outliers", ascending=False)
df_outlier.index.name = "features"

table = df_outlier.head()
features_over = df_outlier.index[df_outlier.loc[:, "percent"] > 5.0]
```

Bien qu'il y ait `{python} len(features_over)` features dépassant les `5%` d'outliers, on considère que la transformation des données est valide.

```{python} 
table
```


## Recherche des hyper paramètres

On considère deux modèles, un SVM et un Random Forest. Actuellement on essaie d'optimiser les hyper paramètres uniquement du SVM. On étudie pour cela deux hyper paramètres `C` et `gamma`.

### C

`C` représente la marge d'erreur que l'on autorise. S'il est petit, alors on autorise des erreurs de classification. Au contraire, avec une grande valeur, on est plus strict mais avec un risque d'overfitting

### Gamma

`Gamma` représente la distance à laquelle un élément éloigné a une influence sur les vecteurs de support. Si `gamma` est faible alors les éléments éloigné auront une influence, si élevé, seuls les éléments proches auront une influence.

### Résultats

En utilisant un shuffle split stratifié, on obtient les paramètres optimaux suivants:

| C | Gamma |
|---|---|
|`{python} params_desc['SVM']['C']` | `{python} params_desc['SVM']['gamma']` |

## Résultats de l'entrainement

 Après apprentissage on trouve:

| Modèle | Accuracy | Matthews Correlation Coefficient |
|---|---|---|
|Random Forest | `{python} f"{metrics_desc['RFC']['ACCURACY']:.2f}"` | `{python} f"{metrics_desc['RFC']['MCC']:.2f}"` |
|SVM | `{python} f"{metrics_desc['SVM']['ACCURACY']:.2f}"` | `{python} f"{metrics_desc['SVM']['MCC']:.2f}"` |

### Matrices de confusion

::: {layout-ncol=2}

![RFC](./graphs/cm_RFC.svg){#fig-cm_rfc}

![SVM](./graphs/cm_SVM.svg){#fig-cm_svm}

:::

## Exemple de prédictions

```{python}
pd.DataFrame(data["PREDICTION_EXEMPLE"])
```