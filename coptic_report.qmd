---
title: "Coptic OCR"
lang: fr
author: "Antenainaskara"
echo: False
format: 
    pdf:
        toc: true
        toc-depth: 2
        toc-title: Table des Matières
        number-sections: true
        colorlinks: true
        default-image-extension: tex
        fig-pos: 'h'
    revealjs:
        toc-depth: 2
        toc-title: Table des Matières
        slide-level: 3
    docx:
        toc: true
        toc-depth: 2
        toc-title: Table des Matières
        number-sections: true
        colorlinks: true
        default-image-extension: tex
        fig-pos: 'h'
jupyter: python3
---

::: {.content-visible when-format="pdf"}

\newpage

:::

## Objectif du projet

L'objectif du projet est de construire un modèle statistique permettant d'effectuer la reconnaissance optique de caractères de l'alphabet copte. On appelle ce procédé l'OCR pour *optical character recognition* en anglais.

Pour remplir cet objectif, j'ai choisi par simplicité d'utiliser une technique se basant uniquement sur du Machine Learning. C'est à dire en calculant des features spécifiques et en effectuant l'apprentissage de deux modèles différents, un `SVM` (Support Machine Vector) et un `Random Forest`, aussi appelé dans la suite `RFC`.

### Cadrage du projet

Il s'agit d'un projet de classification en contexte supervisé. En effet, on veut à partir d'une image d'un caractère copte, calculer un vecteur de features et l'utiliser pour prédire la lettre copte associée à l'image. Ici, on utilisera le terme de classes pour parler de lettres coptes.

### Plan du rapport

Ce rapport sera construit de manière chronologique, c'est-à-dire en présentant les étapes successives permettant de construire ces modèles (`SVM` et `RFC`). 

Aussi, on commencera par une description de la base de données, puis des features calculées, ensuite on présentera l'ensemble des transformations appliquées à nos données, puis des stratégies utilisées pour réduire la quantité de features, puis de l'entrainement des modèles et la recherche d'hyperparamètres et pour finir on parlera des perfomances des divers modèles générés.

::: {.content-visible when-format="pdf"}

\newpage

:::

```{python}
import yaml

with open(f"report/OCR_coptic_16_l1_report.yaml", "r") as file:
    data_16_l1 = yaml.safe_load(file)
data_16_l1 = data_16_l1["states"]

with open(f"report/OCR_coptic_16_None_report.yaml", "r") as file:
    data_16_None = yaml.safe_load(file)
data_16_None = data_16_None["states"]

with open(f"report/OCR_coptic_784_None_report.yaml", "r") as file:
    data_784_None = yaml.safe_load(file)
data_784_None = data_784_None["states"]

with open(f"report/OCR_coptic_784_l1_report.yaml", "r") as file:
    data_784_l1 = yaml.safe_load(file)
data_784_l1 = data_784_l1["states"]

nb_letters = data_16_l1["initial_data"]["shape"][0]
```

## Description de la base de données

La base de données se compose de `{python} nb_letters` images de taille `28x28` en niveau de gris. Ainsi chaque pixel de l'image prend une valeur comprise en `0` pour du noir et `255` pour du blanc.

### Valeurs cibles

```{python}
dict_letter = data_16_l1["after_letter_to_remove"]["metadata"]["LETTER_REMOVED"]

str_letter = ", ".join([f"`{l}`" for l in dict_letter])
images_letter = ", ".join([f"{l}" for l in dict_letter.values()])
targets = data_16_l1["initial_data"]["metadata"]["TARGET"]
features = data_16_l1["initial_data"]["metadata"]["FEATURES"]
npatches = data_16_l1["initial_data"]["metadata"]["NB_PATCHES"]
```

::: {.content-visible when-format="pdf"}

On dénombre `{python} len(targets)` lettres copte dans notre base de données. Cependant `{python} str_letter` seront retirées car n'ayant pas assez d'images associées (respectivement `{python} images_letter`). La base de données se comporte donc de `{python} len(targets) - len(dict_letter)` classes effectives et de `{python} data_16_l1["after_letter_to_remove"]["shape"][0]` images, aussi appelées `samples` dans ce contexte.

:::

![Distribution des lettres](./graph/graphs_16_l1/dataset.svg){#fig-split}

On peut déjà conclure que notre jeu de données n'est pas équilibré et que cela pourra engendrer des difficultés à détecter les lettres les moins fréquentes. On sait aussi que l'`accuracy`, la métrique par défaut utilisée en machine learning sera moines pertinente. On lui préférera un indicateur pouvant gérer le deséquilibre de classe comme le `coefficient de corrélation de Matthews`, qui sera noté `MCC` par la suite.

Une possibilité pour régler ce déséquilibre serait la génération de données artificielles. On pourrait, pour les lettres les moins présentes, générer des images similaires en introduisant des bruits gaussiens ou en les tournant légèrement.

::: {.content-visible when-format="pdf"}

\newpage

:::

## Description des features

Chaque image est découpée en `{python} npatches` patches chevauchant qui recouvre la moitié des patches voisins. Pour chaque patch, on calcule la moyenne et la variance des niveaux de gris donnant ainsi `{python} len(features)` features par image.

Chaque patch ayant une position sur l'image, on peut consistuer une nouvelle image à partir des moyennes des patches et une autre à partir des variances. Concernant les variances, celles-ci étant par nature homogène au carré de la moyenne, leur représentation directe comme image en niveau de gris n'aurait pas de sens. Aussi, on affiche à la place l'écart-type des niveaux de gris qui est suffisamment proche de la variance pour une représentation visuelle.

Exemple pour une lettre `qima`:

::: {layout-ncol=3}

![Qima](./Images_Traitees/qima/objet_1_585.png){#fig-letter width=40%}

![Features moyennes](`{python} f"./export/{npatches}patches/qima/example_mean_qima.png"`){#fig-features width=40%}

![Features "variance"](`{python} f"./export/{npatches}patches/qima/example_std_qima.png"`){#fig-features width=40%}

:::

Exemple pour une lettre `Fai`:

::: {layout-ncol=3}

![Fai](./Images_Traitees/Fai/objet_1_83.png){#fig-letter width=40%}

![Features moyennes](`{python} f"./export/{npatches}patches/Fai/example_mean_Fai.png"`){#fig-features width=40%}

![Features "variance"](`{python} f"./export/{npatches}patches/Fai/example_std_Fai.png"`){#fig-features width=40%}

:::

### Analyse des features

On remarquera, grace à cette visualisation, que les features moyennes permettent de conserver des informations concernant la forme d'un caractère et la "variance" permettant de mettre en avant les zones sans variabilité, donc potentiellement faibles en information.

En un sens, les features moyennes fonctionnent comme une forme de compression et le nombre de patches choisi aura un effet sur la "qualité" de la compression. Ce choix sera donc un compromis entre réduire efficacement le nombre de features initiales et garder suffisamment d'information.

Exemple pour la même lettre `qima` pour `9` et `25` patches:

::: {layout-ncol=3}

![Qima](./Images_Traitees/qima/objet_1_585.png){#fig-letter width=40%}

![Moyennes 9](./export/9patches/qima/example_mean_qima.png){#fig-features width=40%}

!["Variance" 9](./export/9patches/qima/example_std_qima.png){#fig-features width=40%}

:::

::: {layout-ncol=3}

![Qima](./Images_Traitees/qima/objet_1_585.png){#fig-letter width=40%}

![Moyennes 25](./export/25patches/qima/example_mean_qima.png){#fig-features width=40%}

!["Variance" 25](./export/25patches/qima/example_std_qima.png){#fig-features width=40%}

:::

### Justification des features

Afin de sélectionner un nombre raisonnable de features initiales, le choix a été fait de ne garder que les moyennes et variances des patches, mais d'autres features plus complexes auraient pu être envisagées. Les transformées de Fourier réelles, les moments de Zernike mais aussi l'histogramme des gradients orientés (aussi appelé `HOG`) sont des candidats potentiels pour rajouter plus de complexité aux modèles.

Concernant le découpage l'image en patches chevauchant, l'idée était d'imiter des opérations de convolution qui sont utilisées en analyse d'image en tant que moyennes pondérées prenant en compte le voisinage. Ici chaque patch chevauche la moitié des patches voisins et chaque feature garde donc une partie de l'information de ses voisins.

### Comparaison avec un entrainement naïf

Afin de vérifier que les features par 16 patches sont pertinentes, chaque modèle sera entrainé deux fois, une fois en utilisant les features telles que décrites dans cette section et une fois en utilisant l'image entière comme features, soit avec `784` features. Dans la suite, le premier sera qualifié de modèle `16_patches` et le second de modèle `whole_image`.

::: {.content-visible when-format="pdf"}

\newpage

:::

## Transformation des données

Comme indiqué dans [la documentation de scikit-learn concernant les `SVM`](https://scikit-learn.org/stable/modules/svm.html#tips-on-practical-use), les `SVM` sont sensibles aux changements d'échelle, il est donc « hautement recommendé de mettre les données à la même échelle ».

### Mise à l'échelle par normalisation

Aussi d'éviter des problèmes numériques et des imprécisions lors de l'apprentissage, il est nécessaire de transformer les features pour les rapprocher de l'intervalle `[-1, 1]`. De plus les features moyennes et variance ne sont pas sur la même échelle, les moyennes étant entre `0` et `255` et les variances entre `0` et environ `16 000`. Il sera utilisé un Standard Scaler: $z = \frac{x - m}{s}$ avec $m$ la moyenne et $s$ l'écart-type.

![Affichage des features avant et après mise à l'échelle](./graph/graphs_16_None/scaling.svg){#fig-scaling}

### Mise à l'échelle et valeurs aberrantes

Tout comme il est indiqué dans [la documentation sur les transformations de mise à l'échelle](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py), la normalisation standard est sensible aux valeurs aberrantes. Dans notre cas, les features étant bornées, ie la moyenne entre `0` et `255` et les variances entre `0` et environ `16 000`, la vérification sur la présence de valeurs aberrantes n'est pas nécessaire.

Par curiosité, la méthode `MAD` (pour Median Absolute Distance) a été utilisée pour calculer le nombre de valeurs aberrantes potentielles. Pour rappel, on concidère que, dans un cas non-borné, la mise à l'échelle reste valide tant qu'on ne dépasse pas `5%` de valeurs aberrantes par features.

```{python}
nb_outliers = data_16_l1["initial_data"]["metadata"]["OUTLIERS_ANALYSIS"]["nb_outliers"]
pc_outliers = data_16_l1["initial_data"]["metadata"]["OUTLIERS_ANALYSIS"]["percent"]

import pandas as pd
df_outlier = pd.DataFrame({"nb_outliers": nb_outliers, "percent": pc_outliers})
df_outlier = df_outlier.sort_values(by="nb_outliers", ascending=False)
df_outlier.index.name = "features"
df_outlier.index = df_outlier.index.map(lambda x: f"moyenne_{x}" if x < npatches else f"variance_{x-npatches}")

features_over = df_outlier[df_outlier.loc[:, "percent"] > 5.0]
```

```{python} 
features_over
```

Ici, on affiche le nombre de valeurs aberrantes potentielles par features dépassant les `5%` de valeurs aberrantes. 

::: {.content-visible when-format="revealjs"}

---

:::

::: {.content-visible when-format="pdf"}

\newpage

:::

## Sélection des Features

Reduction
Différente approches testées en validation croisée

## Entrainement des modèles

### Séparation ensemble d'apprentissage et de test

L'entrainement des modèles est effectué sur un ensemble de données, appelées données d'entrainement qui compose classiquement `80%` du jeu de données initial. 

```{python}
train_percent = f"{data_16_l1['train_test_split']['metadata']['TRAIN_SIZE']['percent']:.2f}"
test_percent = f"{data_16_l1['train_test_split']['metadata']['TEST_SIZE']['percent']:.2f}"
```

| Jeu de données | Nombre d'images |
|--|--|
| TOTAL | `{python} data_16_l1["train_test_split"]["shape"][0]`
| TRAIN | `{python} data_16_l1["train_test_split"]["metadata"]["TRAIN_SIZE"]["value"]` (`{python} train_percent`%)
| TEST | `{python} data_16_l1["train_test_split"]["metadata"]["TEST_SIZE"]["value"]` (`{python} test_percent`%)

Afin d'éviter que certaines classes soient sous ou sur représentées dans l'ensemble d'entrainement, la séparation des données est stratifiée. Le graphe suivant montre l'effet de cette stratification. Chaque classe est découpée en deux parties, une pour l'entrainement et une pour le test.

![Séparation stratifiée des classes](./graph/graphs_16_l1/split.svg){#fig-split}

::: {.content-visible when-format="pdf"}

\newpage

:::

### Recherche des hyperparamètres

On a retenu deux catégories de modèles, `SVM` et un `Random Forest`. On cherche à optimiser les hyperparamètres uniquement du SVM. On étudie pour cela deux hyper paramètres `C` et `gamma`.

#### C

`C` représente la marge d'erreur que l'on autorise. S'il est petit, alors on autorise des erreurs de classification. Au contraire, avec une grande valeur, on est plus strict mais avec un risque d'overfitting

#### Gamma

`Gamma` représente la distance à laquelle un élément éloigné a une influence sur les vecteurs de support. Si `gamma` est faible alors les éléments éloigné auront une influence, si élevé, seuls les éléments proches auront une influence.

#### Résultats

La recherche de `C` et `gamma` se fait via une recherche de grille. Chaque combinaison de paramètre `C` et `gamma` est testée `5` fois par validation croisée. Comme indiqué dans la description des données, on utilise le `MCC` pour évaluer la qualité générale de l'apprentissage d'un modèle.

Avec les résultats finaux:

| Features | Sélection | C | Gamma |
|---|---|---|---|
| `16_patches` |sans |`{python} f"{data_16_None['model_search_svm']['metadata']['model_params']['C']:.2f}"` | `{python} f"{data_16_None['model_search_svm']['metadata']['model_params']['gamma']:.2f}"` |
| |avec | `{python} f"{data_16_l1['model_search_svm']['metadata']['model_params']['C']:.2f}"` | `{python} f"{data_16_l1['model_search_svm']['metadata']['model_params']['gamma']:.2f}"` |
| `whole_image` |sans | `{python} f"{data_784_None['model_search_svm']['metadata']['model_params']['C']:.2f}"` | `{python} f"{data_784_None['model_search_svm']['metadata']['model_params']['gamma']:.2f}"` |
| |avec | `{python} f"{data_784_l1['model_search_svm']['metadata']['model_params']['C']:.2f}"` | `{python} f"{data_784_l1['model_search_svm']['metadata']['model_params']['gamma']:.2f}"` |

On remarquera que pour les modèles `16_patches` on retrouve des coefficients similaires, ce qui est pas le cas pour `whole_image`. Cela tend à indiquer 

::: {.content-visible when-format="pdf"}

\newpage

:::

## Résultats de l'entrainement

 Après apprentissage on trouve:

| Features | Sélection           | Modèle   | Accuracy | MCC |
|---|---|---|---|---|
| `16_patches` | sans  | Random Forest | `{python} f"{data_16_None['eval_rfc']['metadata']['accuracy_score']:.2f}"` | `{python} f"{data_16_None['eval_rfc']['metadata']['matthews_corrcoef']:.2f}"` |
| |       | SVM    | `{python} f"{data_16_None['eval_search_svm']['metadata']['accuracy_score']:.2f}"` | `{python} f"{data_16_None['eval_search_svm']['metadata']['matthews_corrcoef']:.2f}"` |
| |avec   | Random Forest | `{python} f"{data_16_l1['eval_rfc']['metadata']['accuracy_score']:.2f}"` | `{python} f"{data_16_l1['eval_rfc']['metadata']['matthews_corrcoef']:.2f}"` |
| |       | SVM | `{python} f"{data_16_l1['eval_search_svm']['metadata']['accuracy_score']:.2f}"` | `{python} f"{data_16_l1['eval_search_svm']['metadata']['matthews_corrcoef']:.2f}"` |
| `whole_image` | sans  | Random Forest | `{python} f"{data_784_None['eval_rfc']['metadata']['accuracy_score']:.2f}"` | `{python} f"{data_784_None['eval_rfc']['metadata']['matthews_corrcoef']:.2f}"` |
| |       | SVM    | `{python} f"{data_784_None['eval_search_svm']['metadata']['accuracy_score']:.2f}"` | `{python} f"{data_784_None['eval_search_svm']['metadata']['matthews_corrcoef']:.2f}"` |
| |avec   | Random Forest | `{python} f"{data_784_l1['eval_rfc']['metadata']['accuracy_score']:.2f}"` | `{python} f"{data_784_l1['eval_rfc']['metadata']['matthews_corrcoef']:.2f}"` |
| |       | SVM | `{python} f"{data_784_l1['eval_search_svm']['metadata']['accuracy_score']:.2f}"` | `{python} f"{data_784_l1['eval_search_svm']['metadata']['matthews_corrcoef']:.2f}"` |


### Conclusion

On trouvera en appendice B les matrices de confusions pour les huits modèles pour avoir des résultats plus précis. On remarque des les modèles sans sélection de features donnent de meilleurs résultats que ce soit au niveau global ou en analysant classe par classe, des résultats qu'on pourrait qualifier de très bons, $MCC > 0.95$. On remarque ensuite que les deux features (`whole_image` et `16_patches`) donne des résultats extrêmement proches, confirmant l'intuition concernant le choix des features `16_patches` pour résumer l'image entière.

Ensuite, concernant les modèles incorporant une sélection de features, on remarque une baisse drastique de la qualité des modèles. Cependant les features `16_patches` conservent un `MCC` correct, autour de $0.66$, alors que le modèle `whole_image` est désastreux avec un `MCC` proche de $0.44$ et la seule instance où les performances du `SVM` est en deça de celui du `RFC`.

Les matrices de confusions ne permettent pas de dégager une structure particulière, sauf concernant les classes `Khi` et `Dianda` qui possèdent systématiquement (mais à un degré différent) des confusions entre elles. Ces deux classes possédant un nombre raisonnable de samples (plus de 200), il est fort probable qu'il ne s'agisse pas d'un artefact associé au deséquilibre des classes.

::: {layout-ncol=3}

![Dandia](./Images_Traitees/Dandia/objet_1_3.png){#fig-letter width=50%}

![Khi](./Images_Traitees/Khi/objet_1_256.png){#fig-features width=50%}

:::

En affichant les deux lettres, on se rend compte qu'elles sont extrêmement similaires et que ce soit les features moyennes/variances ou les pixels eux-mêmes, ils ne permettent pas des les distinguer correctement.

::: {.content-visible when-format="pdf"}

\newpage

:::

## Exemple de prédictions

```{python}
pd.DataFrame(data_16_None["example"]["metadata"])
pd.DataFrame(data_16_l1["example"]["metadata"])
pd.DataFrame(data_784_None["example"]["metadata"])
pd.DataFrame(data_784_l1["example"]["metadata"])
```

::: {.content-visible when-format="pdf"}

\newpage

:::

## Appendice A, la recherche d'hyperparamètres

### 16_patches sans sélection

![Heatmap des MCC moyens pour chaque combinaison de paramètres C et gamma pour le modèle 16_patches sans sélection](./graph/graphs_16_None/search_SVC.svg)

::: {.content-visible when-format="pdf"}

\newpage

:::

### 16_patches avec sélection

![Heatmap des MCC moyens pour chaque combinaison de paramètres C et gamma pour le modèle 16_patches avec sélection](./graph/graphs_16_l1/search_SVC.svg)

::: {.content-visible when-format="pdf"}

\newpage

:::

### whole_image sans sélection

![Heatmap des MCC moyens pour chaque combinaison de paramètres C et gamma pour le modèle whole_image sans sélection](./graph/graphs_784_None/search_SVC.svg)

::: {.content-visible when-format="pdf"}

\newpage

:::

### whole_image avec sélection

![Heatmap des MCC moyens pour chaque combinaison de paramètres C et gamma pour le modèle whole_image avec sélection](./graph/graphs_784_l1/search_SVC.svg)

## Appendice B, les matrices de confusion

### 16_patches sans sélection

::: {layout-nrow=2}

![RFC pour modèle 16_patches sans sélection](./graph/graphs_16_None/cm_eval_RFC.svg){#fig-features width=40%}

![SVM pour modèle 16_patches sans sélection](./graph/graphs_16_None/cm_eval_search_svm.svg){#fig-features width=40%}

:::

### 16_patches avec sélection

::: {layout-nrow=2}

![RFC pour modèle 16_patches avec sélection](./graph/graphs_16_l1/cm_eval_RFC.svg){#fig-features width=40%}

![SVM pour modèle 16_patches avec sélection](./graph/graphs_16_l1/cm_eval_search_svm.svg){#fig-features width=40%}

:::

### whole_image sans sélection

::: {layout-nrow=2}

![RFC pour modèle whole_image sans sélection](./graph/graphs_784_None/cm_eval_RFC.svg){#fig-features width=40%}

![SVM pour modèle whole_image sans sélection](./graph/graphs_784_None/cm_eval_search_svm.svg){#fig-features width=40%}

:::

### whole_image avec sélection

::: {layout-nrow=2}

![RFC pour modèle whole_image avec sélection](./graph/graphs_784_l1/cm_eval_RFC.svg){#fig-features width=40%}

![SVM pour modèle whole_image avec sélection](./graph/graphs_784_l1/cm_eval_search_svm.svg){#fig-features width=40%}

:::
